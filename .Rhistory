install.packages("reader")
library(readr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
# Read the data set
data <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, skip = 2) # Skip first two rows
col_names <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, nrows = 1) # Read only the first row as column names
colnames(data) <- col_names # Assigns row 1 header to data
# Remove columns with margin of error
cols_to_remove <- grep("M$", col_names)
data <- data[, -cols_to_remove, drop = FALSE]
# Remove last NA column
data <- data[, -ncol(data), drop = FALSE]
new_col_names <- Code_book[[3]] # Extract the third column
library(readr)
Code_Book <- read_csv("Data/Code Book.csv")
View(Code_Book)
install.packages("reader")
library(readr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
# Read the data set
data <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, skip = 2) # Skip first two rows
col_names <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, nrows = 1) # Read only the first row as column names
colnames(data) <- col_names # Assigns row 1 header to data
# Remove columns with margin of error
cols_to_remove <- grep("M$", col_names)
data <- data[, -cols_to_remove, drop = FALSE]
# Remove last NA column
data <- data[, -ncol(data), drop = FALSE]
new_col_names <- Code_book[[3]] # Extract the third column
install.packages("reader")
library(readr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
# Read the data set
data <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, skip = 2) # Skip first two rows
col_names <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, nrows = 1) # Read only the first row as column names
colnames(data) <- col_names # Assigns row 1 header to data
# Remove columns with margin of error
cols_to_remove <- grep("M$", col_names)
data <- data[, -cols_to_remove, drop = FALSE]
# Remove last NA column
data <- data[, -ncol(data), drop = FALSE]
new_col_names <- Code_book[[3]] # Extract the third column
install.packages("reader")
library(readr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
# Read the data set
data <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, skip = 2) # Skip first two rows
col_names <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, nrows = 1) # Read only the first row as column names
colnames(data) <- col_names # Assigns row 1 header to data
# Remove columns with margin of error
cols_to_remove <- grep("M$", col_names)
data <- data[, -cols_to_remove, drop = FALSE]
# Remove last NA column
data <- data[, -ncol(data), drop = FALSE]
new_col_names <- Code_Book[[3]] # Extract the third column
# Replace the headers with new_col_names
colnames(data) <- new_col_names
# Categorial states in regions
data <- data %>%
mutate(
Region = case_when(
State %in% c("Connecticut", "Maine", "Massachusetts", "New Hampshire", "Rhode Island", "Vermont") ~ "New England",
State %in% c("Delaware", "District of Columbia", "Maryland", "New Jersey", "New York", "Pennsylvania") ~ "Mideast",
State %in% c("Illinois", "Indiana", "Michigan", "Ohio", "Wisconsin") ~ "Great Lakes",
State %in% c("Iowa", "Kansas", "Minnesota", "Missouri", "Nebraska", "North Dakota", "South Dakota") ~ "Plains",
State %in% c("Alabama", "Arkansas", "Florida", "Georgia", "Kentucky", "Louisiana", "Mississippi", "North Carolina", "South Carolina", "Tennessee", "Virginia", "West Virginia") ~ "Southeast",
State %in% c("Arizona", "New Mexico", "Oklahoma", "Texas") ~ "Southwest",
State %in% c("Colorado", "Idaho", "Montana", "Utah", "Wyoming") ~ "Rocky Mountain",
State %in% c("Puerto Rico") ~ "Puerto Rico",
State %in% c("Alaska", "California", "Hawaii", "Nevada", "Oregon", "Washington") ~ "Far West",
TRUE ~ NA_character_
)
)
# New column for proportion of people with no internet access or no computer
data <- data %>%
mutate(
Prop_no_Comp = (data$`HS no Comp`+ data$`< HS no Comp`+ data$`BA+  no Comp`)/data$`State Total`
)
ggplot(data, aes(Region)) +
geom_bar(fill ="skyblue") +
labs(title = "Bureau of Economic Analysis Regions",
y = "Number of States") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_y_continuous(breaks = seq(0, 15, by = 1))
summary_data <- data %>%
group_by(Region) %>%
summarise(
mean_no_Comp = mean(Prop_no_Comp),
median_no_Comp = median(Prop_no_Comp)
)
# Create the bar plot
ggplot(summary_data, aes(x = Region, y = mean_no_Comp)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(x = "", y = "Proportion with No Computers") +
ggtitle("Bureau of Economic Analysis Regions") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(data, aes(x = `State Total`)) +
geom_histogram(binwidth = 1000000, fill = "skyblue", color = "black") +
labs(title = "State Population Distribution",
x = "Population in Millions",
y = "Number of States") +
scale_y_continuous(breaks = seq(0, 14, by = 2),
labels = function(x) format(x, scientific = FALSE)) +
scale_x_continuous(breaks = seq(0, max(data$`State Total`), by = 5e6),
labels = function(x) format(x / 1e6, scientific = FALSE, big.mark = ",")) +
theme_minimal()
ggplot(data, aes(x = Prop_no_Comp)) +
geom_histogram(bins = 50, fill = 'red', color = 'black') +
labs(title = 'No Computer or Internet Access Distribution',
x = 'Proportion',
y = 'Number of States') +
facet_wrap(~ Region)
library(readr)
Edu_Comp_22 <- read_csv("Data/Edu_Comp_22.csv")
View(Edu_Comp_22)
library(readr)
library(tidyverse)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
Edu_Comp_22 <- read_csv("Data/Edu_Comp_22.csv")
Code_book <- read_csv("Data/Code Book.csv")
library(readr)
library(tidyverse)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
# Read the data set
data <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, skip = 2) # Skip first two rows
col_names <- read.csv("Data/Edu_Comp_22.csv", header = FALSE, nrows = 1) # Read only the first row as column names
colnames(data) <- col_names # Assigns row 1 header to data
# Remove columns with margin of error
cols_to_remove <- grep("M$", col_names)
data <- data[, -cols_to_remove, drop = FALSE]
Code_Book <- read_csv("Data/Code Book.csv")
new_col_names <- Code_Book[[3]]
# Remove last NA column
data <- data[, -ncol(data), drop = FALSE]
# Replace the headers with new_col_names
colnames(data) <- new_col_names
# Categorial states in regions
data <- data %>%
mutate(
Region = case_when(
State %in% c("Connecticut", "Maine", "Massachusetts", "New Hampshire", "Rhode Island", "Vermont") ~ "New England",
State %in% c("Delaware", "District of Columbia", "Maryland", "New Jersey", "New York", "Pennsylvania") ~ "Mideast",
State %in% c("Illinois", "Indiana", "Michigan", "Ohio", "Wisconsin") ~ "Great Lakes",
State %in% c("Iowa", "Kansas", "Minnesota", "Missouri", "Nebraska", "North Dakota", "South Dakota") ~ "Plains",
State %in% c("Alabama", "Arkansas", "Florida", "Georgia", "Kentucky", "Louisiana", "Mississippi", "North Carolina", "South Carolina", "Tennessee", "Virginia", "West Virginia") ~ "Southeast",
State %in% c("Arizona", "New Mexico", "Oklahoma", "Texas") ~ "Southwest",
State %in% c("Colorado", "Idaho", "Montana", "Utah", "Wyoming") ~ "Rocky Mountain",
State %in% c("Puerto Rico") ~ "Puerto Rico",
State %in% c("Alaska", "California", "Hawaii", "Nevada", "Oregon", "Washington") ~ "Far West",
TRUE ~ NA_character_
)
)
library(tidyr)
# Currently it includes people with computers and proper internet access but that can be fixed by just removing that column in a copy of the data table
data_enum <- pivot_longer(data, cols = contains("Comp", ignore.case = FALSE), names_to = "Tech_Access_Group", values_to = "Count")
# New column for proportion of people with no computer or internet access
data <- data %>%
mutate(
Prop_no_Comp = (`< HS no Comp`+ `< HS w/Comp w/out IS`+ `HS no Comp`+ `HS some Col w/Comp w/out IS`+ `BA+  no Comp` + `BA+  w/Comp w/out IS`)/`State Total`
)
# New columns for proportion of people with no internet access or no computer by education level, that is a conditional probability, P(no_Comp|education level)
data <- data %>%
mutate(
lths_Prop_no_Comp = ((`< HS no Comp`+ `< HS w/Comp w/out IS`)/`< HS Total`),
hs_Prop_no_Comp = ((`HS no Comp`+ `HS some Col w/Comp w/out IS`)/`HS some Col Total`),
ba_Prop_no_Comp = ((`BA+  no Comp` + `BA+  w/Comp w/out IS`)/`BA+ Total`))
# New columns for proportion of people with no internet access or no computer by education level, that is a conditional probability, P(no_Comp|education level)
data <- data %>%
mutate(
lths_Prop_no_Comp = ((`< HS no Comp`+ `< HS w/Comp w/out IS`)/`< HS Total`),
hs_Prop_no_Comp = ((`HS no Comp`+ `HS some Col w/Comp w/out IS`)/`HS some Col Total`),
ba_Prop_no_Comp = ((`BA+  no Comp` + `BA+  w/Comp w/out IS`)/`BA+ Total`))
ggplot(data, aes(Region)) +
geom_bar(fill ="skyblue") +
labs(title = "Bureau of Economic Analysis Regions",
y = "Number of States") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_y_continuous(breaks = seq(0, 15, by = 1))
summary_data <- data %>%
group_by(Region) %>%
summarise(
mean_no_Comp = mean(Prop_no_Comp),
median_no_Comp = median(Prop_no_Comp)
)
# Create the bar plot
ggplot(summary_data, aes(x = Region, y = mean_no_Comp)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(x = "Bureau of Economic Analysis Regions", y = "Proportion") +
ggtitle("USA: No Computer or Internet Access") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(data_enum, aes(x = State, y = Count, fill = Tech_Access_Group)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Breakdown of number of people with different tech access levels in each state",
x = "State",
y = "Count",
fill = "Tech Access Group") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
data_enum2 <- data_enum %>%
group_by(Region) %>%
summarize(mean = mean(Count, na.rm = TRUE))
ggplot(data_enum2, aes(x = Region, y = mean, fill = Tech_Access_Group)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Dodged Barplot",
x = "State",
y = "Average number of people in each tech access group",
fill = "Tech Access Group") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
View(data_enum2)
View(data_enum)
library(devtools)
library(obsval)
library(mvtnorm)
library(nnet)
library(MASS)
library(usethis)
library(haven)
library(ggplot2)
library(dplyr)
library(stargazer)
library(forecast)
library(tseries)
library(tidyverse)
library(broom)
#load my data
myData <- read_dta("sop2021JLCdata.dta")
